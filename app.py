# -*- coding: utf-8 -*-
import io, re
from datetime import datetime, date, timedelta
import chardet
import pandas as pd
import requests
import streamlit as st

# ==============================
# ìƒìˆ˜ / ê²½ë¡œ
# ==============================
TARGET_OCHUL = 0.00019   # 0.019%
TARGET_NUL   = 0.00041   # 0.041%
OCHUL_STATUS = "êµì°¨ì˜¤ë°°ë¶„"
NUL_STATUS   = "ìƒì‚°ëˆ„ë½"
OF_LABEL     = "OFê·€ì±…"

DATA_URL   = "https://raw.githubusercontent.com/jinwookyung-kurly-data/-/main/ì˜¤ì¶œìë™í™”_test_927.csv"
TOTALS_URL = "https://raw.githubusercontent.com/jinwookyung-kurly-data/-/main/total.csv"

# ==============================
# ìœ í‹¸ í•¨ìˆ˜
# ==============================
def load_csv_safely(url: str) -> pd.DataFrame:
    """GitHub raw csv ì•ˆì „ ë¡œë”"""
    try:
        r = requests.get(url)
        r.raise_for_status()
        raw = r.content
        enc = (chardet.detect(raw).get("encoding") or "utf-8")
        text = raw.decode(enc, errors="replace")
        return pd.read_csv(io.StringIO(text))
    except Exception as e:
        st.warning(f"âš ï¸ {url} ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def parse_korean_date(q: str, available_dates: list[date]) -> date | None:
    """'ì˜¤ëŠ˜', 'ì–´ì œ', '2025.09.27' ë“±ì˜ ì…ë ¥ íŒŒì‹±"""
    if not q: return None
    q = q.strip()
    today = datetime.today().date()
    if "ì˜¤ëŠ˜" in q:  return today
    if "ì–´ì œ" in q:  return today - timedelta(days=1)
    if "ê·¸ì œ" in q or "ê·¸ì €ê»˜" in q: return today - timedelta(days=2)
    m = re.search(r"(\d{4})[.\-\/]\s?(\d{1,2})[.\-\/]\s?(\d{1,2})", q) or re.search(r"(\d{4})(\d{2})(\d{2})", q)
    if m:
        y, mth, d = map(int, m.groups())
        try:
            want = date(y, mth, d)
        except ValueError:
            return None
        return want if want in available_dates else (min(available_dates, key=lambda x: abs(x - want)) if available_dates else None)
    return None

def pct(x: float) -> str: return f"{x*100:.3f}%"
def pp(x: float)  -> str: return f"{x*100:+.3f} pp"

# ==============================
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==============================
st.set_page_config(page_title="ëˆ„ë½ í˜„í™© ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ëˆ„ë½ í˜„í™© ëŒ€ì‹œë³´ë“œ ")

st.caption("ì˜¤ì¶œ=êµì°¨ì˜¤ë°°ë¶„, ëˆ„ë½=ìƒì‚°ëˆ„ë½. **ì‹¤ì œìœ¨=OFê·€ì±…ë§Œ**, **ì¶”ì •ìœ¨=ì „ì²´ ê¸°ì¤€**. "
           "ë¶„ëª¨(ì „ì²´ ìœ ë‹›)ëŠ” `total.csv`ì˜ `Total_unit`ì„ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ==============================
# ë°ì´í„° ë¡œë“œ
# ==============================
uploaded = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])
df = pd.read_csv(uploaded, encoding="utf-8-sig") if uploaded else load_csv_safely(DATA_URL)
if uploaded is None:
    st.info("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    st.success("ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš© ì¤‘.")

# ì»¬ëŸ¼ ì •ë¦¬
rename_map = {"í¬ì¥ì™„ë£Œë¡œ":"í¬ì¥ì™„ë£Œì‹œê°„","ë¶„ë¥˜ì™„ë£Œë¡œ":"ë¶„ë¥˜ì™„ë£Œì‹œê°„","í¬ì¥ì™„ë£Œ":"í¬ì¥ì™„ë£Œì‹œê°„","ë¶„ë¥˜ì™„ë£Œ":"ë¶„ë¥˜ì™„ë£Œì‹œê°„"}
df.rename(columns=rename_map, inplace=True)
df.columns = df.columns.str.replace("\ufeff","",regex=True).str.strip()

expected = ["ë‚ ì§œ","ì£¼ë¬¸ë²ˆí˜¸","ìœ ë‹›","íƒ€ì…","ìƒíƒœ","í¬ì¥ì™„ë£Œì‹œê°„","ë¶„ë¥˜ì™„ë£Œì‹œê°„","í¬ì¥ì‘ì—…ì","í’‹ì›”ì‘ì—…ì","ì‚¬ìœ ","ê·€ì±…"]
missing = [c for c in expected if c not in df.columns]
if missing:
    st.error(f"âŒ CSV í—¤ë” í˜•ì‹ ë¶ˆì¼ì¹˜\në¹ ì§„ ì»¬ëŸ¼: {missing}")
    st.stop()

# í˜• ë³€í™˜
df["ìœ ë‹›"] = pd.to_numeric(df["ìœ ë‹›"], errors="coerce").fillna(0).astype(int)
df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"], errors="coerce").dt.date
df["is_ochul"] = df["ìƒíƒœ"].astype(str).str.contains(OCHUL_STATUS, na=False)
df["is_nul"]   = df["ìƒíƒœ"].astype(str).str.contains(NUL_STATUS,   na=False)
df["is_of"]    = df["ê·€ì±…"].astype(str).str.replace(" ","").str.upper().eq(OF_LABEL.upper())

dates = sorted(df["ë‚ ì§œ"].dropna().unique().tolist())
if not dates:
    st.error("ë‚ ì§œë¥¼ í•´ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

# ==============================
# total.csv ë¡œë“œ
# ==============================
totals_df = load_csv_safely(TOTALS_URL)
totals_map: dict[date,int] = {}
if not totals_df.empty:
    totals_df.columns = totals_df.columns.str.strip()
    if "Total_unit" in totals_df.columns and "D" in totals_df.columns:
        totals_df["Total_unit"] = totals_df["Total_unit"].astype(str).str.replace(",","",regex=False)
        totals_df["Total_unit"] = pd.to_numeric(totals_df["Total_unit"], errors="coerce").fillna(0).astype(int)
        totals_df["D_date"] = pd.to_datetime(totals_df["D"], errors="coerce").dt.date
        totals_map = {d:int(u) for d,u in totals_df[["D_date","Total_unit"]].dropna().itertuples(index=False, name=None)}

# ==============================
# ë‚ ì§œ ì„ íƒ
# ==============================
with st.sidebar:
    st.header("ğŸ” ìì—°ì–´ ë‚ ì§œ ì„ íƒ")
    q = st.text_input("ì˜ˆ) 'ì˜¤ëŠ˜', 'ì–´ì œ', '2025/09/27'")
    st.divider()
    man_date = st.selectbox("ğŸ“… ë‚ ì§œ ì„ íƒ", dates, index=len(dates)-1)

parsed = parse_korean_date(q, dates) if q else None
selected_date = parsed or man_date
if parsed:
    st.success(f"ğŸ—“ ì¸ì‹ëœ ë‚ ì§œ: **{selected_date}**")

# ==============================
# ì„ íƒ ì¼ì ìš”ì•½ (ìœ ë‹› ê¸°ì¤€)
# ==============================
day = df[df["ë‚ ì§œ"] == selected_date].copy()
if day.empty:
    st.warning("ì„ íƒí•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

den = int(totals_map.get(selected_date, int(day["ìœ ë‹›"].sum()) or 1))
ochul_all = int(day.loc[day["is_ochul"], "ìœ ë‹›"].sum())
ochul_of  = int(day.loc[day["is_ochul"] & day["is_of"], "ìœ ë‹›"].sum())
nul_all   = int(day.loc[day["is_nul"],   "ìœ ë‹›"].sum())
nul_of    = int(day.loc[day["is_nul"]   & day["is_of"], "ìœ ë‹›"].sum())

act_ochul = (ochul_of  / den) if den else 0.0
est_ochul = (ochul_all / den) if den else 0.0
act_nul   = (nul_of    / den) if den else 0.0
est_nul   = (nul_all   / den) if den else 0.0

st.subheader(f"ğŸ“Œ {selected_date} ìš”ì•½ (ì´ Unit={den:,})")
c1, c2, c3, c4 = st.columns(4)
c1.metric("ì˜¤ì¶œ(ì‹¤ì œ:OF)",  pct(act_ochul), pp(act_ochul - TARGET_OCHUL))
c2.metric("ì˜¤ì¶œ(ì¶”ì •:ì „ì²´)", pct(est_ochul), pp(est_ochul - TARGET_OCHUL))
c3.metric("ëˆ„ë½(ì‹¤ì œ:OF)",  pct(act_nul),   pp(act_nul   - TARGET_NUL))
c4.metric("ëˆ„ë½(ì¶”ì •:ì „ì²´)", pct(est_nul),   pp(est_nul   - TARGET_NUL))

# ==============================
# ìƒíƒœê°’ ìš”ì•½
# ==============================
st.markdown("### ğŸ§© ìƒíƒœê°’ ìš”ì•½")
status_summary = (
    day["ìƒíƒœ"]
      .astype(str)
      .value_counts()
      .reset_index()
      .rename(columns={"index": "ìƒíƒœ", "ìƒíƒœ": "ê±´ìˆ˜"})
)
st.dataframe(status_summary, use_container_width=True)

# ==============================
# ê·€ì±… ì œì™¸ What-if (ì¶”ì •ìœ¨ ê¸°ì¤€)
# ==============================
st.markdown("### ğŸ§® ê·€ì±… ì œì™¸ What-if (ì¶”ì •ìœ¨ ê¸°ì¤€)")
blame_options = sorted([b for b in df["ê·€ì±…"].dropna().astype(str).str.strip().unique().tolist()])
exclude_blames = st.multiselect("ì œì™¸í•  ê·€ì±… ì„ íƒ", options=blame_options)

if exclude_blames:
    mask_keep = ~day["ê·€ì±…"].astype(str).str.strip().isin(exclude_blames)
    adj_ochul_all = int(day.loc[mask_keep & day["is_ochul"], "ìœ ë‹›"].sum())
    adj_nul_all   = int(day.loc[mask_keep & day["is_nul"],   "ìœ ë‹›"].sum())

    adj_est_ochul = (adj_ochul_all / den) if den else 0.0
    adj_est_nul   = (adj_nul_all   / den) if den else 0.0

    st.write(f"**ì œì™¸ëœ ê·€ì±…:** {', '.join(exclude_blames)}")

    tbl = pd.DataFrame({
        "í•­ëª©": ["ì˜¤ì¶œìœ¨(ì¶”ì •:ì „ì²´)", "ëˆ„ë½ìœ¨(ì¶”ì •:ì „ì²´)"],
        "ê¸°ì¡´(%)": [est_ochul*100, est_nul*100],
        "ì¡°ì •(%)": [adj_est_ochul*100, adj_est_nul*100],
        "ë³€í™”(pp)": [(adj_est_ochul-est_ochul)*100, (adj_est_nul-est_nul)*100],
        "íƒ€ê²ŸëŒ€ë¹„(pp)": [
            (adj_est_ochul - TARGET_OCHUL)*100,
            (adj_est_nul   - TARGET_NUL)*100
        ]
    })
    st.dataframe(tbl.round(3), use_container_width=True)
else:
    st.caption("ì™¼ìª½ì—ì„œ ì œì™¸í•  ê·€ì±…ì„ ì„ íƒí•˜ë©´ ì¡°ì • ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

# ==============================
# ì‚¬ìœ  TOP + ê·€ì±…ë³„ ìš”ì•½
# ==============================
st.markdown("### ğŸ§¾ ì‚¬ìœ  TOP")
reason_top = (
    day.groupby("ì‚¬ìœ ")["ìœ ë‹›"]
       .agg(ê±´ìˆ˜="size", ìœ ë‹›="sum")
       .reset_index()
       .rename(columns={"ì‚¬ìœ ": "reason"})
       .sort_values("ìœ ë‹›", ascending=False)
)
st.dataframe(reason_top.head(15), use_container_width=True)

st.markdown("### âš™ï¸ ê·€ì±…ë³„ ì¹´ìš´íŠ¸ ìš”ì•½")
blame_summary = (
    day.groupby("ê·€ì±…")["ìœ ë‹›"]
       .agg(ê±´ìˆ˜="size", ìœ ë‹›í•©ê³„="sum")
       .reset_index()
       .sort_values("ìœ ë‹›í•©ê³„", ascending=False)
)
st.dataframe(blame_summary, use_container_width=True)

# ==============================
# ì „ì²´ ë°ì´í„° ë³´ê¸°
# ==============================
st.markdown("### ğŸ“Š ì •ë¦¬ëœ ë°ì´í„° ì—´ëŒ")
with st.expander("ğŸ“‚ ì „ì²´ ë°ì´í„° ë³´ê¸°"):
    st.dataframe(df, use_container_width=True, height=500)
with st.expander("ğŸ“… ì„ íƒ ì¼ì ë°ì´í„° ë³´ê¸°"):
    st.dataframe(day, use_container_width=True, height=400)
