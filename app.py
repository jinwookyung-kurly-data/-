# -*- coding: utf-8 -*-
import io, re
from datetime import datetime, date, timedelta
import chardet
import pandas as pd
import requests
import streamlit as st

# ==============================
# ìƒìˆ˜ / ê²½ë¡œ
# ==============================
TARGET_OCHUL = 0.00019   # 0.019%
TARGET_NUL   = 0.00041   # 0.041%
OCHUL_STATUS = "êµì°¨ì˜¤ë°°ë¶„"
NUL_STATUS   = "ìƒì‚°ëˆ„ë½"
OF_LABEL     = "OFê·€ì±…"

DATA_URL = "https://raw.githubusercontent.com/jinwookyung-kurly-data/-/blob/main/ì˜¤ì¶œìë™í™”_test_927.csv"
TOTALS_URL = "https://raw.githubusercontent.com/jinwookyung-kurly-data/-/main/total.csv"

# ==============================
# ìœ í‹¸ í•¨ìˆ˜
# ==============================
def load_csv_from_url(url: str) -> pd.DataFrame:
    """GitHub raw csv ì•ˆì „ ë¡œë”"""
    try:
        r = requests.get(url)
        r.raise_for_status()
        raw = r.content
        enc = (chardet.detect(raw).get("encoding") or "utf-8")
        text = raw.decode(enc, errors="replace")
        return pd.read_csv(io.StringIO(text))
    except Exception as e:
        st.warning(f"âš ï¸ {url} ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def parse_korean_date(q: str, available_dates: list[date]) -> date | None:
    """'ì˜¤ëŠ˜', 'ì–´ì œ', '2025.09.27' ë“±ì˜ ì…ë ¥ íŒŒì‹±"""
    if not q: return None
    q = q.strip()
    today = datetime.today().date()
    if "ì˜¤ëŠ˜" in q:  return today
    if "ì–´ì œ" in q:  return today - timedelta(days=1)
    if "ê·¸ì œ" in q or "ê·¸ì €ê»˜" in q: return today - timedelta(days=2)
    m = re.search(r"(\d{4})[.\-\/]\s?(\d{1,2})[.\-\/]\s?(\d{1,2})", q) or re.search(r"(\d{4})(\d{2})(\d{2})", q)
    if m:
        y, mth, d = map(int, m.groups())
        try:
            want = date(y, mth, d)
        except ValueError:
            return None
        return want if want in available_dates else (min(available_dates, key=lambda x: abs(x - want)) if available_dates else None)
    return None

def pct(x: float) -> str: return f"{x*100:.3f}%"
def pp(x: float)  -> str: return f"{x*100:+.3f} pp"

def build_totals_map(totals_df: pd.DataFrame) -> dict:
    """
    total.csv â†’ { ë‚ ì§œ(date): Total_unit(int) }
    ì»¬ëŸ¼ ì´ë¦„ ìœ ì—° ì²˜ë¦¬: ë‚ ì§œëŠ” D ë˜ëŠ” ë‚ ì§œ, ìœ ë‹›ì€ Total_unit
    """
    if totals_df.empty:
        return {}
    df = totals_df.copy()
    df.columns = df.columns.str.strip()

    # ë‚ ì§œ ì»¬ëŸ¼ í›„ë³´
    date_col = None
    for cand in ["D", "ë‚ ì§œ", "date", "Date"]:
        if cand in df.columns:
            date_col = cand
            break
    if date_col is None:
        st.warning("total.csv ì— ë‚ ì§œ ì»¬ëŸ¼(D/ë‚ ì§œ)ì´ ì—†ì–´ ë¶„ëª¨ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    if "Total_unit" not in df.columns:
        st.warning("total.csv ì— Total_unit ì»¬ëŸ¼ì´ ì—†ì–´ ë¶„ëª¨ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    # ìˆ«ì ì •ë¦¬
    df["Total_unit"] = (
        df["Total_unit"].astype(str).str.replace(",", "", regex=False)
    )
    df["Total_unit"] = pd.to_numeric(df["Total_unit"], errors="coerce").fillna(0).astype(int)

    # ë‚ ì§œ íŒŒì‹± (ì—¬ëŸ¬ í¬ë§· í—ˆìš©)
    dstr = df[date_col].astype(str)
    dstr = dstr.str.replace(" ", "")
    dstr = dstr.str.replace("ë…„", "-").str.replace("ì›”", "-").str.replace("ì¼", "")
    dstr = dstr.str.replace(r"[.]", "-", regex=True)
    df["__date__"] = pd.to_datetime(dstr, errors="coerce").dt.date

    mp = {d: int(u) for d, u in df[["__date__", "Total_unit"]].dropna().itertuples(index=False, name=None)}
    return mp

# ==============================
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==============================
st.set_page_config(page_title="ì˜¤ì¶œ ë° ëˆ„ë½ í˜„í™© ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ì˜¤ì¶œ ë° ëˆ„ë½ í˜„í™© ëŒ€ì‹œë³´ë“œ ")

st.caption(
    "ì˜¤ì¶œ=êµì°¨ì˜¤ë°°ë¶„, ëˆ„ë½=ìƒì‚°ëˆ„ë½. **ì‹¤ì œìœ¨=OFê·€ì±…ë§Œ**, **ì¶”ì •ìœ¨=ì „ì²´ ê¸°ì¤€**. "
    "ë¶„ëª¨(ì „ì²´ ìœ ë‹›)ëŠ” `total.csv`ì˜ `Total_unit`ì„ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤. "
    "ì•„ë˜ì—ì„œ **total.csvë„ ì—…ë¡œë“œ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

# ==============================
# ë°ì´í„° ë¡œë“œ (ë³¸ ë°ì´í„° + total.csv)
# ==============================
col_up1, col_up2 = st.columns([2, 1])
with col_up1:
    uploaded = st.file_uploader("ğŸ“„ ëˆ„ë½/ì˜¤ì¶œ CSV ì—…ë¡œë“œ", type=["csv"], key="data_csv")
with col_up2:
    uploaded_totals = st.file_uploader("ğŸ“ˆ total.csv ì—…ë¡œë“œ (ì„ íƒ)", type=["csv"], key="totals_csv")

# ë³¸ ë°ì´í„°
df = pd.read_csv(uploaded, encoding="utf-8-sig") if uploaded else load_csv_from_url(DATA_URL)
if uploaded is None:
    st.info("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    st.success("ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš© ì¤‘.")

# total.csv
if uploaded_totals is not None:
    try:
        totals_df = pd.read_csv(uploaded_totals, encoding="utf-8-sig")
        st.success("ì—…ë¡œë“œëœ total.csv ì‚¬ìš© ì¤‘.")
    except Exception:
        totals_df = pd.read_csv(uploaded_totals)  # ì¸ì½”ë”© ìë™
        st.success("ì—…ë¡œë“œëœ total.csv ì‚¬ìš© ì¤‘.")
else:
    totals_df = load_csv_from_url(TOTALS_URL)
    if totals_df.empty:
        st.warning("total.csv ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¹ì¼ ë¶„ëª¨ëŠ” ì—…ë¡œë“œ CSVì˜ ìœ ë‹› í•©ê³„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        st.info("ìƒ˜í”Œ total.csv ì‚¬ìš© ì¤‘.")

# ì»¬ëŸ¼ ì •ë¦¬
rename_map = {"í¬ì¥ì™„ë£Œë¡œ":"í¬ì¥ì™„ë£Œì‹œê°„","ë¶„ë¥˜ì™„ë£Œë¡œ":"ë¶„ë¥˜ì™„ë£Œì‹œê°„","í¬ì¥ì™„ë£Œ":"í¬ì¥ì™„ë£Œì‹œê°„","ë¶„ë¥˜ì™„ë£Œ":"ë¶„ë¥˜ì™„ë£Œì‹œê°„"}
df.rename(columns=rename_map, inplace=True)
df.columns = df.columns.str.replace("\ufeff","",regex=True).str.strip()

expected = ["ë‚ ì§œ","ì£¼ë¬¸ë²ˆí˜¸","ìœ ë‹›","íƒ€ì…","ìƒíƒœ","í¬ì¥ì™„ë£Œì‹œê°„","ë¶„ë¥˜ì™„ë£Œì‹œê°„","í¬ì¥ì‘ì—…ì","í’‹ì›”ì‘ì—…ì","ì‚¬ìœ ","ê·€ì±…"]
missing = [c for c in expected if c not in df.columns]
if missing:
    st.error(f"âŒ CSV í—¤ë” í˜•ì‹ ë¶ˆì¼ì¹˜\në¹ ì§„ ì»¬ëŸ¼: {missing}")
    st.stop()

# í˜• ë³€í™˜
df["ìœ ë‹›"] = pd.to_numeric(df["ìœ ë‹›"], errors="coerce").fillna(0).astype(int)
df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"], errors="coerce").dt.date
df["is_ochul"] = df["ìƒíƒœ"].astype(str).str.contains(OCHUL_STATUS, na=False)
df["is_nul"]   = df["ìƒíƒœ"].astype(str).str.contains(NUL_STATUS,   na=False)
df["is_of"]    = df["ê·€ì±…"].astype(str).str.replace(" ","").str.upper().eq(OF_LABEL.upper())

dates = sorted(df["ë‚ ì§œ"].dropna().unique().tolist())
if not dates:
    st.error("ë‚ ì§œë¥¼ í•´ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

# total.csv â†’ map
totals_map = build_totals_map(totals_df)

# ==============================
# ë‚ ì§œ ì„ íƒ
# ==============================
with st.sidebar:
    st.header("ğŸ” ìì—°ì–´ ë‚ ì§œ ì„ íƒ")
    q = st.text_input("ì˜ˆ) 'ì˜¤ëŠ˜', 'ì–´ì œ', '2025/09/27'")
    st.divider()
    man_date = st.selectbox("ğŸ“… ë‚ ì§œ ì„ íƒ", dates, index=len(dates)-1)

parsed = parse_korean_date(q, dates) if q else None
selected_date = parsed or man_date
if parsed:
    st.success(f"ğŸ—“ ì¸ì‹ëœ ë‚ ì§œ: **{selected_date}**")

# ==============================
# ì„ íƒ ì¼ì ìš”ì•½ (ìœ ë‹› ê¸°ì¤€)
# ==============================
day = df[df["ë‚ ì§œ"] == selected_date].copy()
if day.empty:
    st.warning("ì„ íƒí•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

den = int(totals_map.get(selected_date, int(day["ìœ ë‹›"].sum()) or 1))

# ë¶„ì(ìœ ë‹›)
ochul_all = int(day.loc[day["is_ochul"], "ìœ ë‹›"].sum())
ochul_of  = int(day.loc[day["is_ochul"] & day["is_of"], "ìœ ë‹›"].sum())
nul_all   = int(day.loc[day["is_nul"],   "ìœ ë‹›"].sum())
nul_of    = int(day.loc[day["is_nul"]   & day["is_of"], "ìœ ë‹›"].sum())

# ë¹„ìœ¨
act_ochul = (ochul_of  / den) if den else 0.0
est_ochul = (ochul_all / den) if den else 0.0
act_nul   = (nul_of    / den) if den else 0.0
est_nul   = (nul_all   / den) if den else 0.0

st.subheader(f"ğŸ“Œ {selected_date} ìš”ì•½ (ì´ Unit={den:,})")
c1, c2, c3, c4 = st.columns(4)
c1.metric("ì˜¤ì¶œ(ì‹¤ì œ:OF)",  pct(act_ochul), pp(act_ochul - TARGET_OCHUL))
c2.metric("ì˜¤ì¶œ(ì¶”ì •:ì „ì²´)", pct(est_ochul), pp(est_ochul - TARGET_OCHUL))
c3.metric("ëˆ„ë½(ì‹¤ì œ:OF)",  pct(act_nul),   pp(act_nul   - TARGET_NUL))
c4.metric("ëˆ„ë½(ì¶”ì •:ì „ì²´)", pct(est_nul),   pp(est_nul   - TARGET_NUL))

# ==============================
# ìƒíƒœê°’ ìš”ì•½ (ê±´ìˆ˜ + ìœ ë‹›í•©ê³„)
# ==============================
st.markdown("### ğŸ§© ìƒíƒœê°’ ìš”ì•½")
status_summary = (
    day.groupby("ìƒíƒœ")
      .agg(ê±´ìˆ˜=("ìœ ë‹›", "size"), ìœ ë‹›í•©ê³„=("ìœ ë‹›", "sum"))
      .reset_index()
      .sort_values("ìœ ë‹›í•©ê³„", ascending=False)
)
st.dataframe(status_summary, use_container_width=True)

# ==============================
# ê·€ì±… ì œì™¸ What-if (ì¶”ì •ìœ¨ ê¸°ì¤€, ìœ ë‹›ë„ í•¨ê»˜)
# ==============================
st.markdown("### ğŸ§® ê·€ì±… ì œì™¸ What-if (ì¶”ì •ìœ¨ ê¸°ì¤€, ìœ ë‹› í¬í•¨)")
blame_options = sorted([b for b in df["ê·€ì±…"].dropna().astype(str).str.strip().unique().tolist()])
exclude_blames = st.multiselect("ì œì™¸í•  ê·€ì±… ì„ íƒ", options=blame_options)

if exclude_blames:
    mask_keep = ~day["ê·€ì±…"].astype(str).str.strip().isin(exclude_blames)

    # ì œì™¸ í›„ ìœ ë‹›(ë¶„ì)
    adj_ochul_all = int(day.loc[mask_keep & day["is_ochul"], "ìœ ë‹›"].sum())
    adj_nul_all   = int(day.loc[mask_keep & day["is_nul"],   "ìœ ë‹›"].sum())

    # ë¹„ìœ¨
    adj_est_ochul = (adj_ochul_all / den) if den else 0.0
    adj_est_nul   = (adj_nul_all   / den) if den else 0.0

    tbl = pd.DataFrame({
        "í•­ëª©":        ["ì˜¤ì¶œ(ì¶”ì •:ì „ì²´)", "ëˆ„ë½(ì¶”ì •:ì „ì²´)"],
        "ê¸°ì¡´ìœ ë‹›":     [ochul_all,         nul_all],
        "ì¡°ì •ìœ ë‹›":     [adj_ochul_all,     adj_nul_all],
        "ë³€í™”ìœ ë‹›":     [adj_ochul_all - ochul_all, adj_nul_all - nul_all],
        "ê¸°ì¡´(%)":      [est_ochul*100,     est_nul*100],
        "ì¡°ì •(%)":      [adj_est_ochul*100, adj_est_nul*100],
        "ë³€í™”(pp)":     [(adj_est_ochul-est_ochul)*100, (adj_est_nul-est_nul)*100],
        "íƒ€ê²ŸëŒ€ë¹„(pp)": [(adj_est_ochul - TARGET_OCHUL)*100,
                      (adj_est_nul   - TARGET_NUL)*100],
    })
    st.dataframe(tbl.round(3), use_container_width=True)
else:
    st.caption("ì™¼ìª½ì—ì„œ ì œì™¸í•  ê·€ì±…ì„ ì„ íƒí•˜ë©´ ì¡°ì • ìœ ë‹›/ë¹„ìœ¨ì´ í‘œì‹œë©ë‹ˆë‹¤.")

# ==============================
# ì‚¬ìœ  TOP + ê·€ì±…ë³„ ìš”ì•½
# ==============================
st.markdown("### ğŸ§¾ ì‚¬ìœ  TOP")
reason_top = (
    day.groupby("ì‚¬ìœ ")["ìœ ë‹›"]
       .agg(ê±´ìˆ˜="size", ìœ ë‹›="sum")
       .reset_index()
       .rename(columns={"ì‚¬ìœ ": "reason"})
       .sort_values("ìœ ë‹›", ascending=False)
)
st.dataframe(reason_top.head(15), use_container_width=True)

st.markdown("### âš™ï¸ ê·€ì±…ë³„ ì¹´ìš´íŠ¸ ìš”ì•½")
blame_summary = (
    day.groupby("ê·€ì±…")["ìœ ë‹›"]
       .agg(ê±´ìˆ˜="size", ìœ ë‹›í•©ê³„="sum")
       .reset_index()
       .sort_values("ìœ ë‹›í•©ê³„", ascending=False)
)
st.dataframe(blame_summary, use_container_width=True)

# ==============================
# OF ê¸°ì¤€ ì‘ì—…ì ë¡œê·¸ + ì‘ì—…ìë³„ ìš”ì•½
# ==============================
of_fail = day[(day["is_of"]) & (day["is_ochul"] | day["is_nul"])].copy()

st.markdown("### ğŸ‘· ì‘ì—…ìë³„ ë¡œê·¸ (OF ê¸°ì¤€ Â· êµì°¨ì˜¤ë°°ë¶„/ìƒì‚°ëˆ„ë½)")
if of_fail.empty:
    st.info("OF ê¸°ì¤€ì˜ êµì°¨ì˜¤ë°°ë¶„/ìƒì‚°ëˆ„ë½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    of_fail["í¬ì¥ì™„ë£Œì‹œê°„"] = of_fail["í¬ì¥ì™„ë£Œì‹œê°„"].astype(str)
    tabs = st.tabs(["í¬ì¥ ì‘ì—…ì ë¡œê·¸", "í’‹ì›” ì‘ì—…ì ë¡œê·¸"])

    with tabs[0]:
        pack_log = of_fail[["í¬ì¥ì‘ì—…ì", "ìƒíƒœ", "í¬ì¥ì™„ë£Œì‹œê°„"]].rename(
            columns={"í¬ì¥ì‘ì—…ì": "ì‘ì—…ì"}
        ).sort_values(["ì‘ì—…ì", "í¬ì¥ì™„ë£Œì‹œê°„"])
        st.dataframe(pack_log, use_container_width=True)

    with tabs[1]:
        put_log = of_fail[["í’‹ì›”ì‘ì—…ì", "ìƒíƒœ", "í¬ì¥ì™„ë£Œì‹œê°„"]].rename(
            columns={"í’‹ì›”ì‘ì—…ì": "ì‘ì—…ì"}
        ).sort_values(["ì‘ì—…ì", "í¬ì¥ì™„ë£Œì‹œê°„"])
        st.dataframe(put_log, use_container_width=True)

    st.markdown("### ğŸ“¦ ì‘ì—…ìë³„ ëˆ„ë½/ì˜¤ì¶œ ì¹´ìš´íŠ¸ ìš”ì•½ (OF ê¸°ì¤€)")
    colA, colB = st.columns(2)

    def worker_summary(df_src: pd.DataFrame, worker_col: str) -> pd.DataFrame:
        g = (
            df_src.groupby(worker_col)
                  .apply(lambda x: pd.Series({
                      "ì˜¤ì¶œê±´ìˆ˜": int((x["is_ochul"]).sum()),
                      "ëˆ„ë½ê±´ìˆ˜": int((x["is_nul"]).sum()),
                      "ì˜¤ì¶œìœ ë‹›": int(x.loc[x["is_ochul"], "ìœ ë‹›"].sum()),
                      "ëˆ„ë½ìœ ë‹›": int(x.loc[x["is_nul"], "ìœ ë‹›"].sum()),
                  }))
                  .reset_index()
                  .rename(columns={worker_col: "ì‘ì—…ì"})
                  .sort_values(["ì˜¤ì¶œê±´ìˆ˜", "ëˆ„ë½ê±´ìˆ˜", "ì˜¤ì¶œìœ ë‹›", "ëˆ„ë½ìœ ë‹›"], ascending=False)
        )
        return g

    with colA:
        st.write("**í¬ì¥ì‘ì—…ì ìš”ì•½**")
        st.dataframe(worker_summary(of_fail, "í¬ì¥ì‘ì—…ì"), use_container_width=True)

    with colB:
        st.write("**í’‹ì›”ì‘ì—…ì ìš”ì•½**")
        st.dataframe(worker_summary(of_fail, "í’‹ì›”ì‘ì—…ì"), use_container_width=True)

# ==============================
# ì „ì²´ ë°ì´í„° ë³´ê¸°
# ==============================
st.markdown("### ğŸ“Š ì •ë¦¬ëœ ë°ì´í„° ì—´ëŒ")
with st.expander("ğŸ“‚ ì „ì²´ ë°ì´í„° ë³´ê¸°"):
    st.dataframe(df, use_container_width=True, height=500)
with st.expander("ğŸ“… ì„ íƒ ì¼ì ë°ì´í„° ë³´ê¸°"):
    st.dataframe(day, use_container_width=True, height=400)
